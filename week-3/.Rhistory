), align = "l")
library(ggplot2)
library(ggthemes)
install.packages("ggthemea")
install.packages("ggthemes")
install.packages("virids")
install.packages("viridis")
library(ggplot2)
library(ggthemes)
library(viridis)
ggplot(open_data_happiness,
aes(x = Openness,
y = Happiness)) +
geom_point(aes(colour = Region),
size = 2) +
geom_smooth(method="lm") +
labs(x = "Openness Score",
y = "Happiness Score",
title = "Are open data friendly countries happy countries?",
subtitle = "Data openness and happiness by country in 2015") +
scale_color_viridis(discrete = T) +
theme_minimal() +
theme(text = element_text(size=16))
library(ggplot2)
library(ggthemes)
library(viridis)
ggplot(country_2015,
aes(x = Openness,
y = Happiness)) +
geom_point(aes(colour = Region),
size = 2) +
geom_smooth(method="lm") +
labs(x = "Openness Score",
y = "Happiness Score",
title = "Are open data friendly countries happy countries?",
subtitle = "Data openness and happiness by country in 2015") +
scale_color_viridis(discrete = T) +
theme_minimal() +
theme(text = element_text(size=16))
library(ggplot2)
library(ggthemes)
library(viridis)
ggplot(country_2015,
aes(x = Openness,
y = Happiness)) +
geom_point(aes(colour = Region),
size = 2) +
geom_smooth(method="lm") +
labs(x = "Openness Score",
y = "Happiness Score",
title = "Are open data friendly countries happy countries?",
subtitle = "Data openness and happiness by country in 2015") +
scale_color_viridis(discrete = T)
library(ggplot2)
library(ggthemes)
library(viridis)
ggplot(country_2015,
aes(x = Openness,
y = Happiness)) +
geom_point(aes(colour = Region),
size = 2) +
geom_smooth(method="lm") +
labs(x = "Openness Score",
y = "Happiness Score",
title = "Are open data friendly countries happy countries?",
subtitle = "Data openness and happiness by country in 2015") +
scale_color_viridis(discrete = T) +
theme_minimal()
library(ggplot2)
library(ggthemes)
library(viridis)
ggplot(country_2015,
aes(x = Openness,
y = Happiness)) +
geom_point(aes(colour = Region),
size = 2) +
geom_smooth(method="lm") +
labs(x = "Openness Score",
y = "Happiness Score",
title = "Are open data friendly countries happy countries?",
subtitle = "Data openness and happiness by country in 2015") +
scale_color_viridis(discrete = T) +
theme_minimal()+
theme(text = element_text(size=16))
library(ggplot2)
library(ggthemes)
library(viridis)
ggplot(country_2015,
aes(x = Openness,
y = Happiness)) +
geom_point(aes(colour = Region),
size = 2)
library(ggplot2)
library(ggthemes)
library(viridis)
ggplot(country_2015,
aes(x = Openness,
y = Happiness)) +
geom_point(aes(colour = Region),
size = 2)+
geom_smooth(method="lm") +
labs(x = "Openness Score",
y = "Happiness Score",
title = "Are open data friendly countries happy countries?",
subtitle = "Data openness and happiness by country in 2015") +
scale_color_viridis(discrete = T) +
theme_minimal() +
theme(text = element_text(size=16))
library(ggplot2)
library(ggthemes)
library(viridis)
ggplot(country_2015,
aes(x = Openness,
y = Happiness)) +
geom_point(aes(colour = Region),
size = 2)+
geom_smooth(method="lm") +
labs(x = "Openness Score",
y = "Happiness Score",
title = "Are open data friendly countries happy countries?",
subtitle = "Data openness and happiness by country in 2015") +
scale_color_viridis(discrete = R) +
theme_minimal() +
theme(text = element_text(size=16))
library(ggplot2)
library(ggthemes)
library(viridis)
ggplot(country_2015,
aes(x = Openness,
y = Happiness)) +
geom_point(aes(colour = Region),
size = 2)+
geom_smooth(method="lm") +
labs(x = "Openness Score",
y = "Happiness Score",
title = "Are open data friendly countries happy countries?",
subtitle = "Data openness and happiness by country in 2015") +
scale_color_viridis(discrete = T) +
theme_minimal() +
theme(text = element_text(size=16))
install.packages("corroplot")
install.packages("corrplot")
library(corrplot)
country_2015_corr <- country_2015 %>%
select(Openness, Happiness, GDP, Family, Health,
Freedom, Trust, Generosity, DystopiaResidual) %>%
mutate(Openness = as.numeric(Openness))
od_corr <- cor(country_2015_corr, use = "complete", method = "pearson")
corrplot(od_corr)
setwd("~/Documents/GitHub/cs-summer-school/week-3")
install.packages("bitops")
install.packages("httr")
install.packages("Rcurl")
install.packages("XML")
install.packages("tm")
install.packages("NLP")
install.packages("tmcn")
install.packages("jiebaRD")
install.packages("jiebaR")
install.packages("varhandle")
html <- htmlParse( GET(url) )
?htmlParse
??htmlParse
install.packages("XML")
url.list <- xpathSApply( html, "//div[@class='title']/a[@href]", xmlAttrs )
library(RCurl)
library(XML)
from <- 6943 # 2018-07-19
to   <- 6944 # 2018-07-20
prefix = "https://www.ptt.cc/bbs/movie/index"
data <- list()
for( id in c(from:to) )
{
url  <- paste0( prefix, as.character(id), ".html" )
html <- htmlParse( getURL(url) )
url.list <- xpathSApply( html, "//div[@class='title']/a[@href]", xmlAttrs )
data <- rbind( data, as.matrix(paste('https://www.ptt.cc', url.list, sep='')) )
}
data <- unlist(data)
head(data)
install.packages("Rcurl")
install.packages("RCurl")
library(RCurl)
library(XML)
from <- 6943 # 2018-07-19
to   <- 6944 # 2018-07-20
prefix = "https://www.ptt.cc/bbs/movie/index"
data <- list()
for( id in c(from:to) )
{
url  <- paste0( prefix, as.character(id), ".html" )
html <- htmlParse( get(url) )
url.list <- xpathSApply( html, "//div[@class='title']/a[@href]", xmlAttrs )
data <- rbind( data, as.matrix(paste('https://www.ptt.cc', url.list, sep='')) )
}
data <- unlist(data)
head(data)
install.packages("bitops")
install.packages("bitops")
library(RCurl)
library(XML)
from <- 6943 # 2018-07-19
to   <- 6944 # 2018-07-20
prefix = "https://www.ptt.cc/bbs/movie/index"
data <- list()
for( id in c(from:to) )
{
url  <- paste0( prefix, as.character(id), ".html" )
html <- htmlParse( get(url) )
url.list <- xpathSApply( html, "//div[@class='title']/a[@href]", xmlAttrs )
data <- rbind( data, as.matrix(paste('https://www.ptt.cc', url.list, sep='')) )
}
data <- unlist(data)
head(data)
library(RCurl)
library(XML)
from <- 6943 # 2018-07-19
to   <- 6944 # 2018-07-20
prefix = "https://www.ptt.cc/bbs/movie/index"
data <- list()
for( id in c(from:to) )
{
url  <- paste0( prefix, as.character(id), ".html" )
html <- htmlParse( get(url) )
url.list <- xpathSApply( html, "//div[@class='title']/a[@href]", xmlAttrs )
data <- rbind( data, as.matrix(paste('https://www.ptt.cc', url.list, sep='')) )
}
data <- unlist(data)
head(data)
library(RCurl)
library(XML)
from <- 6943 # 2018-07-19
to   <- 6944 # 2018-07-20
prefix = "https://www.ptt.cc/bbs/movie/index"
data <- list()
for( id in c(from:to) )
{
url  <- paste0( prefix, as.character(id), ".html" )
html <- htmlParse( getURL(url) )
url.list <- xpathSApply( html, "//div[@class='title']/a[@href]", xmlAttrs )
data <- rbind( data, as.matrix(paste('https://www.ptt.cc', url.list, sep='')) )
}
data <- unlist(data)
library(dplyr)
getdoc <- function(url)
{
html <- htmlParse( getURL(url) )
doc  <- xpathSApply( html, "//div[@id='main-content']", xmlValue )
time <- xpathSApply( html, "//*[@id='main-content']/div[4]/span[2]", xmlValue )
temp <- gsub( "  ", " 0", unlist(time) )
part <- strsplit( temp, split=" ", fixed=T )
#date <- paste(part[[1]][2], part[[1]][3], part[[1]][5], sep="-")
#date <- paste(part[[1]][2], part[[1]][5], sep="_")
#date <- paste(part[[1]][1], part[[1]][2], sep="_")
timestamp <- part[[1]][4]
timestamp <- strsplit( timestamp, split=":", fixed=T )
hour <- timestamp[[1]][1]
#print(hour)
name <- paste0('./DATA/', hour, ".txt")
write(doc, name, append = TRUE)
}
sapply(data, getdoc)
d.corpus <- Corpus( DirSource("./DATA") )
d.corpus <- tm_map(d.corpus, removePunctuation)
d.corpus <- tm_map(d.corpus, removeNumbers)
d.corpus <- tm_map(d.corpus, function(word) {
gsub("[A-Za-z0-9]", "", word)
})
#進行斷詞，並依照日期建立文本矩陣 TermDocumentMatrix
mixseg = worker()
jieba_tokenizer = function(d)
{
unlist( segment(d[[1]], mixseg) )
}
seg = lapply(d.corpus, jieba_tokenizer)
count_token = function(d)
{
as.data.frame(table(d))
}
tokens = lapply(seg, count_token)
n = length(seg)
TDM = tokens[[1]]
colNames <- names(seg)
colNames <- gsub(".txt", "", colNames)
for( id in c(2:n) )
{
TDM = merge(TDM, tokens[[id]], by="d", all = TRUE)
names(TDM) = c('d', colNames[1:id])
}
TDM[is.na(TDM)] <- 0
library(knitr)
kable(head(TDM))
library(dplyr)
d.corpus <- Corpus( DirSource("./DATA") )
d.corpus <- tm_map(d.corpus, removePunctuation)
d.corpus <- tm_map(d.corpus, removeNumbers)
d.corpus <- tm_map(d.corpus, function(word) {
gsub("[A-Za-z0-9]", "", word)
})
library(tm)
library(tmcn)
library(Rwordseg)
d.corpus <- Corpus( DirSource("./DATA") )
d.corpus <- tm_map(d.corpus, removePunctuation)
d.corpus <- tm_map(d.corpus, removeNumbers)
d.corpus <- tm_map(d.corpus, function(word) {
gsub("[A-Za-z0-9]", "", word)
})
install.packages("NLP")
install.packages("NLP")
install.packages("Rwordseg")
library(tm)
library(tmcn)
d.corpus <- Corpus( DirSource("./DATA") )
d.corpus <- tm_map(d.corpus, removePunctuation)
d.corpus <- tm_map(d.corpus, removeNumbers)
d.corpus <- tm_map(d.corpus, function(word) {
gsub("[A-Za-z0-9]", "", word)
})
mixseg = worker()
jieba_tokenizer = function(d)
{
unlist( segment(d[[1]], mixseg) )
}
seg = lapply(d.corpus, jieba_tokenizer)
count_token = function(d)
{
as.data.frame(table(d))
}
tokens = lapply(seg, count_token)
n = length(seg)
TDM = tokens[[1]]
colNames <- names(seg)
colNames <- gsub(".txt", "", colNames)
for( id in c(2:n) )
{
TDM = merge(TDM, tokens[[id]], by="d", all = TRUE)
names(TDM) = c('d', colNames[1:id])
}
TDM[is.na(TDM)] <- 0
library(knitr)
kable(head(TDM))
library("jiebaR")
mixseg = worker()
jieba_tokenizer = function(d)
{
unlist( segment(d[[1]], mixseg) )
}
seg = lapply(d.corpus, jieba_tokenizer)
count_token = function(d)
{
as.data.frame(table(d))
}
tokens = lapply(seg, count_token)
n = length(seg)
TDM = tokens[[1]]
colNames <- names(seg)
colNames <- gsub(".txt", "", colNames)
for( id in c(2:n) )
{
TDM = merge(TDM, tokens[[id]], by="d", all = TRUE)
names(TDM) = c('d', colNames[1:id])
}
TDM[is.na(TDM)] <- 0
library(knitr)
kable(head(TDM))
View(jieba_tokenizer)
View(TDM)
tf <- apply(as.matrix(TDM[,2:(n+1)]), 2, sum)
library(Matrix)
idfCal <- function(word_doc)
{
log2( n / nnzero(word_doc) )
}
idf <- apply(as.matrix(TDM[,2:(n+1)]), 1, idfCal)
doc.tfidf <- TDM
tempY = matrix(rep(c(as.matrix(tf)), each = length(idf)), nrow = length(idf))
tempX = matrix(rep(c(as.matrix(idf)), each = length(tf)), ncol = length(tf), byrow = TRUE)
doc.tfidf[,2:(n+1)] <- (doc.tfidf[,2:(n+1)] / tempY) * tempX
stopLine = rowSums(doc.tfidf[,2:(n+1)])
delID = which(stopLine == 0)
kable(head(doc.tfidf[delID,1]))
tf <- apply(as.matrix(TDM,2:(n+1)), 2, sum)
tf <- apply(as.matrix(TDM,2:(n+1)), 2, sum)
library(Matrix)
idfCal <- function(word_doc)
{
log2( n / nnzero(word_doc) )
}
idf <- apply(as.matrix(TDM[,2:(n+1)]), 1, idfCal)
doc.tfidf <- TDM
tempY = matrix(rep(c(as.matrix(tf)), each = length(idf)), nrow = length(idf))
tempX = matrix(rep(c(as.matrix(idf)), each = length(tf)), ncol = length(tf), byrow = TRUE)
doc.tfidf[,2:(n+1)] <- (doc.tfidf[,2:(n+1)] / tempY) * tempX
stopLine = rowSums(doc.tfidf[,2:(n+1)])
delID = which(stopLine == 0)
kable(head(doc.tfidf[delID,1]))
install.packages("Rwordseg")
?`as.matrix,Matrix-method`
?as.matrix
tf <- apply(as.matrix(TDM[2:(n+1)]), 2, sum)
library(Matrix)
idfCal <- function(word_doc)
{
log2( n / nnzero(word_doc) )
}
idf <- apply(as.matrix(TDM[2:(n+1)]), 1, idfCal)
doc.tfidf <- TDM
tempY = matrix(rep(c(as.matrix(tf)), each = length(idf)), nrow = length(idf))
tempX = matrix(rep(c(as.matrix(idf)), each = length(tf)), ncol = length(tf), byrow = TRUE)
doc.tfidf[,2:(n+1)] <- (doc.tfidf[,2:(n+1)] / tempY) * tempX
stopLine = rowSums(doc.tfidf[,2:(n+1)])
delID = which(stopLine == 0)
kable(head(doc.tfidf[delID,1]))
tf <- apply(as.matrix(TDM[2:(n+1)]), 2, sum)
tf <- apply(as.matrix(TDM[,2:(n+1)]), 2, sum)
tf <- apply(as.matrix(TDM[,1:(n+1)]), 1, sum)
tf <- apply(as.matrix(TDM,[1:(n+1)], 1, sum)
tf <- apply(as.matrix(TDM[,1:(n+1)], 1, sum)
tf <- apply(as.matrix(TDM[,1:(n+1)], 1, sum)
library(Matrix)
idfCal <- function(word_doc)
{
log2( n / nnzero(word_doc) )
}
idf <- apply(as.matrix(TDM[,2:(n+1)]), 1, idfCal)
doc.tfidf <- TDM
tempY = matrix(rep(c(as.matrix(tf)), each = length(idf)), nrow = length(idf))
tempX = matrix(rep(c(as.matrix(idf)), each = length(tf)), ncol = length(tf), byrow = TRUE)
doc.tfidf[,2:(n+1)] <- (doc.tfidf[,2:(n+1)] / tempY) * tempX
stopLine = rowSums(doc.tfidf[,2:(n+1)])
delID = which(stopLine == 0)
kable(head(doc.tfidf[delID,1]))
tf <- apply(as.matrix(TDM[,1:(n+1)], 1, sum)
library(Matrix)
idfCal <- function(word_doc)
{
log2( n / nnzero(word_doc) )
}
install.packages("Matrix")
install.packages("Matrix")
install.packages("Matrix")
install.packages("Matrix")
install.packages("Matrix")
install.packages("Matrix")
tf <- apply(as.matrix(TDM[,1:(n+1)], 1, sum)
library(Matrix)
idfCal <- function(word_doc)
{
log2( n / nnzero(word_doc) )
}
tf <- apply(as.matrix(TDM[,1:(n+1)], 1, sum)
library(Matrix)
idfCal <- function(word_doc)
{
log2( n / nnzero(word_doc) )
}
idf <- apply(as.matrix(TDM[,2:(n+1)]), 1, idfCal)
install.packages("Matrix")
install.packages("Matrix")
install.packages("Matrix")
install.packages("Matrix")
tf <- apply(as.matrix(TDM[,1:(n+1)], 1, sum)
library(Matrix)
idfCal <- function(word_doc)
{
log2( n / nnzero(word_doc) )
}
idf <- apply(as.matrix(TDM[,1:(n+1)]), 1, idfCal)
doc.tfidf <- TDM
tempY = matrix(rep(c(as.matrix(tf)), each = length(idf)), nrow = length(idf))
tempX = matrix(rep(c(as.matrix(idf)), each = length(tf)), ncol = length(tf), byrow = TRUE)
doc.tfidf[,2:(n+1)] <- (doc.tfidf[,2:(n+1)] / tempY) * tempX
stopLine = rowSums(doc.tfidf[,2:(n+1)])
delID = which(stopLine == 0)
kable(head(doc.tfidf[delID,1]))
tf <- apply(as.matrix(TDM[,1:(n+1)], 1, sum)
library(Matrix)
idfCal <- function(word_doc)
{
log2( n / nnzero(word_doc) )
}
idf <- apply(as.matrix(TDM[,1:(n+1)]), 1, idfCal)
doc.tfidf <- TDM
tempY = matrix(rep(c(as.matrix(tf)), each = length(idf)), nrow = length(idf))
tempX = matrix(rep(c(as.matrix(idf)), each = length(tf)), ncol = length(tf), byrow = TRUE)
doc.tfidf[,2:(n+1)] <- (doc.tfidf[,2:(n+1)] / tempY) * tempX
stopLine = rowSums(doc.tfidf[,2:(n+1)])
delID = which(stopLine == 0)
kable(head(doc.tfidf[delID,1]))
install.packages("Matrix")
install.packages("Matrix")
install.packages("Matrix")
install.packages("Matrix")
install.packages("Matrix")
install.packages("Matrix")
tf <- apply(as.matrix(TDM[,1:(n+1)], 1, sum)
library(Matrix)
idfCal <- function(word_doc)
{
log2( n / nnzero(word_doc) )
}
tf <- apply(as.matrix(TDM[,1:(n+1)], 1, sum)
library("Matrix")
idfCal <- function(word_doc)
{
log2( n / nnzero(word_doc) )
}
idf <- apply(as.matrix(TDM[,1:(n+1)]), 1, idfCal)
tf <- apply(as.matrix(TDM[,1:(n+1)], 1, sum)
tf <- apply(as.matrix(TDM[,1:(n+1)], 1, sum)
library("Matrix")
